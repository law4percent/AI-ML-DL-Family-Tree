<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>AI ‚Üí ML ‚Üí Deep Learning Family Tree (with Math Backbone)</title>
  <link rel="stylesheet" href="style.css">
  
</head>
<body>
  <div class="wrap">
    <header>
      <h1>AI ‚Üí Machine Learning ‚Üí Deep Learning ‚Äî Family Tree (with Mathematical Backbone)</h1>
      <p class="lead">Comprehensive family tree mapping the AI ecosystem with its underlying mathematical foundations, from core concepts to cutting-edge models.</p>
      <div class="legend">
        <span class="pill">üåø Branch = domain (NLP, CV, robotics, etc.)</span>
        <span class="pill">üî∑ Family = related model line</span>
        <span class="pill">‚ú® Model = concrete checkpoint/version</span>
        <span class="pill" style="background: rgba(183,148,246,.15); border-color: #b794f6; color: #b794f6;">üìê Math = mathematical foundation</span>
        <span class="pill" style="background: rgba(255,107,157,.15); border-color: #ff6b9d; color: #ff6b9d;">üî• Hot = trending/breakthrough</span>
        <span class="pill" style="background: rgba(255,217,61,.15); border-color: #ffd93d; color: #ffd93d;">‚ö° Emerging = cutting-edge research</span>
      </div>
    </header>

    <div class="stats">
      <div class="stat-item">
        <div class="stat-number">50+</div>
        <div class="stat-label">Model Families</div>
      </div>
      <div class="stat-item">
        <div class="stat-number">200+</div>
        <div class="stat-label">Individual Models</div>
      </div>
      <div class="stat-item">
        <div class="stat-number">30+</div>
        <div class="stat-label">Math Concepts</div>
      </div>
      <div class="stat-item">
        <div class="stat-number">12</div>
        <div class="stat-label">AI Domains</div>
      </div>
      <div class="stat-item">
        <div class="stat-number">2025</div>
        <div class="stat-label">Latest Updates</div>
      </div>
    </div>


    <!-- AI -->
    <section class="card">
      <details open>
        <summary><span class="branch">Artificial Intelligence (AI)</span> <span class="tag">umbrella field</span></summary>
        
        <!-- Non-ML AI Methods -->
        <details>
          <summary><span class="branch">Symbolic AI / Expert Systems</span> <span class="tag">rule-based</span></summary>
          <div class="desc">Knowledge representation, logic programming, and rule-based reasoning systems.</div>
          <div class="math-desc">Based on formal logic: propositional & predicate calculus, model theory, proof systems</div>
          <details>
            <summary>üî∑ Knowledge Graphs</summary>
            <ul>
              <li class="model">Neo4j Graph Database</li>
              <li class="model">Cypher Query Language</li>
              <li class="model">Google Knowledge Graph</li>
              <li class="math-concept">Graph traversal algorithms, RDF triples</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ Logic Programming</summary>
            <ul>
              <li class="model">Prolog</li>
              <li class="model">Answer Set Programming (ASP)</li>
              <li class="math-concept">Horn clauses, unification, resolution theorem proving</li>
            </ul>
          </details>
        </details>

        <details open>
          <summary><span class="branch">Machine Learning (ML)</span> <span class="tag">learns from data</span></summary>
          
          <!-- Classical ML -->
          <details>
            <summary><span class="branch">Classical Machine Learning</span> <span class="tag">traditional algorithms</span></summary>
            <details>
              <summary>üî∑ Supervised Learning</summary>
              <div class="math-desc">Optimization of loss functions via gradient methods, closed-form solutions</div>
              <ul>
                <li class="model">Linear/Logistic Regression</li>
                <li class="math-concept">Ordinary least squares: Œ≤ = (X^T X)^(-1) X^T y</li>
                <li class="model">Support Vector Machines (SVM)</li>
                <li class="math-concept">Quadratic programming, kernel methods, margin maximization</li>
                <li class="model">Random Forest</li>
                <li class="math-concept">Bootstrap aggregating, information gain, Gini impurity</li>
                <li class="model">XGBoost / LightGBM</li>
                <li class="math-concept">Gradient boosting, second-order Taylor approximation</li>
                <li class="model">Naive Bayes</li>
                <li class="math-concept">Conditional independence assumption, Bayes' theorem</li>
              </ul>
            </details>
            <details>
              <summary>üî∑ Unsupervised Learning</summary>
              <div class="math-desc">Eigenvalue decomposition, clustering metrics, density estimation</div>
              <ul>
                <li class="model">K-Means Clustering</li>
                <li class="math-concept">Lloyd's algorithm, within-cluster sum of squares minimization</li>
                <li class="model">DBSCAN</li>
                <li class="math-concept">Density-based clustering, Œµ-neighborhoods</li>
                <li class="model">Principal Component Analysis (PCA)</li>
                <li class="math-concept">Eigendecomposition of covariance matrix, dimensionality reduction</li>
                <li class="model">t-SNE / UMAP</li>
                <li class="math-concept">Non-linear manifold learning, probabilistic embeddings</li>
              </ul>
            </details>
            <details>
              <summary>üî∑ Ensemble Methods</summary>
              <div class="math-desc">Bias-variance tradeoff, weighted combination of weak learners</div>
              <ul>
                <li class="model">AdaBoost</li>
                <li class="math-concept">Exponential loss minimization, weighted voting</li>
                <li class="model">Gradient Boosting</li>
                <li class="math-concept">Functional gradient descent in function space</li>
                <li class="model">Voting Classifiers</li>
                <li class="math-concept">Majority voting, weighted averaging</li>
              </ul>
            </details>
          </details>

          <!-- Deep Learning -->
          <details open>
            <summary><span class="branch">Deep Learning (DL)</span> <span class="tag">neural networks</span></summary>
            <div class="math-desc">Universal function approximation, backpropagation, stochastic gradient descent</div>

            <!-- NLP -->
            <details>
              <summary>üåø <span class="branch">Natural Language Processing (NLP)</span> <span class="tag">text & language</span></summary>
              <div class="math-desc">Sequence modeling, attention mechanisms, transformer architectures</div>
              <details>
                <summary>üî∑ Large Language Models (LLMs)</summary>
                <div class="desc">Foundation models trained on massive text corpora for general language understanding and generation.</div>
                <div class="math-desc">Autoregressive modeling: P(x‚ÇÅ,...,x‚Çô) = ‚àèP(x·µ¢|x‚ÇÅ,...,x·µ¢‚Çã‚ÇÅ), self-attention, layer normalization</div>
                <details>
                  <summary>GPT Family (OpenAI)</summary>
                  <ul>
                    <li class="model">GPT‚Äë1 <span class="tag">2018</span></li>
                    <li class="model">GPT‚Äë2 <span class="tag">1.5B params</span></li>
                    <li class="model">DistilGPT‚Äë2 <span class="tag">compressed</span></li>
                    <li class="model">GPT‚Äë3 <span class="tag">175B params</span></li>
                    <li class="model">GPT‚Äë3.5‚Äëturbo</li>
                    <li class="model">GPT‚Äë4 / GPT‚Äë4‚Äëturbo</li>
                    <li class="model">GPT‚Äë4o <span class="tag hot">multimodal</span></li>
                    <li class="model">GPT‚Äë4.1 <span class="tag hot">latest</span></li>
                    <li class="model">o1 / o1‚Äëmini <span class="tag hot">reasoning</span></li>
                    <li class="math-concept">Decoder-only transformer, causal attention masking</li>
                  </ul>
                </details>
                <details>
                  <summary>Claude Family (Anthropic)</summary>
                  <ul>
                    <li class="model">Claude 1.0</li>
                    <li class="model">Claude 2.0 / 2.1</li>
                    <li class="model">Claude 3 Haiku <span class="tag">fast</span></li>
                    <li class="model">Claude 3 Sonnet <span class="tag">balanced</span></li>
                    <li class="model">Claude 3 Opus <span class="tag">most capable</span></li>
                    <li class="model">Claude 3.5 Sonnet <span class="tag hot">enhanced</span></li>
                    <li class="model">Claude 4 Sonnet <span class="tag hot">latest</span></li>
                    <li class="math-concept">Constitutional AI, RLHF training, safety objectives</li>
                  </ul>
                </details>
                <details>
                  <summary>Gemini Family (Google)</summary>
                  <ul>
                    <li class="model">LaMDA <span class="tag">conversation</span></li>
                    <li class="model">PaLM / PaLM 2</li>
                    <li class="model">Gemini Pro</li>
                    <li class="model">Gemini Ultra</li>
                    <li class="model">Gemini 1.5 <span class="tag">long context</span></li>
                    <li class="model">Gemini 2.0 <span class="tag hot">multimodal</span></li>
                    <li class="math-concept">Mixture of experts (MoE), Pathways architecture</li>
                  </ul>
                </details>
                <details>
                  <summary>Meta LLaMA Family</summary>
                  <ul>
                    <li class="model">LLaMA 1 <span class="tag">7B-65B</span></li>
                    <li class="model">LLaMA 2 <span class="tag">chat variants</span></li>
                    <li class="model">Code Llama <span class="tag">programming</span></li>
                    <li class="model">LLaMA 3 / 3.1 <span class="tag hot">405B</span></li>
                    <li class="model">LLaMA 3.2 <span class="tag hot">multimodal</span></li>
                    <li class="math-concept">RMSNorm, SwiGLU activation, rotary positional embeddings</li>
                  </ul>
                </details>
                <details>
                  <summary>Open Source Alternatives</summary>
                  <ul>
                    <li class="model">Mistral 7B / 8x7B (Mixtral)</li>
                    <li class="model">Falcon 7B / 40B / 180B</li>
                    <li class="model">Alpaca (Stanford)</li>
                    <li class="model">Vicuna (LMSYS)</li>
                    <li class="model">MPT (MosaicML)</li>
                    <li class="model">Qwen (Alibaba)</li>
                    <li class="model">Yi (01.AI)</li>
                    <li class="math-concept">Various architectural optimizations, efficiency improvements</li>
                  </ul>
                </details>
              </details>
              <details>
                <summary>üî∑ Specialized NLP Models</summary>
                <details>
                  <summary>Understanding Models (Encoders)</summary>
                  <div class="math-desc">Bidirectional attention, masked language modeling objective</div>
                  <ul>
                    <li class="model">BERT / RoBERTa</li>
                    <li class="math-concept">Masked LM: P(x·µ¢|x‚Çã·µ¢), bidirectional transformer</li>
                    <li class="model">DeBERTa</li>
                    <li class="math-concept">Disentangled attention, enhanced mask decoder</li>
                    <li class="model">ELECTRA</li>
                    <li class="math-concept">Replaced token detection, generator-discriminator training</li>
                    <li class="model">DistilBERT <span class="tag">compressed</span></li>
                    <li class="math-concept">Knowledge distillation from teacher to student model</li>
                  </ul>
                </details>
                <details>
                  <summary>Text-to-Text Models</summary>
                  <div class="math-desc">Encoder-decoder architecture, span denoising objectives</div>
                  <ul>
                    <li class="model">T5 / UL2</li>
                    <li class="math-concept">Text-to-text unified framework, span corruption</li>
                    <li class="model">BART</li>
                    <li class="math-concept">Denoising autoencoder, various noise functions</li>
                    <li class="model">Pegasus <span class="tag">summarization</span></li>
                    <li class="math-concept">Gap sentence generation pre-training</li>
                  </ul>
                </details>
                <details>
                  <summary>Embedding Models</summary>
                  <div class="math-desc">Contrastive learning, cosine similarity, semantic vector spaces</div>
                  <ul>
                    <li class="model">Sentence-BERT</li>
                    <li class="math-concept">Siamese networks, triplet loss</li>
                    <li class="model">OpenAI text-embedding-ada-002</li>
                    <li class="model">E5 / BGE</li>
                    <li class="model">Instructor <span class="tag">task-specific</span></li>
                    <li class="math-concept">Task-aware embeddings, instruction following</li>
                  </ul>
                </details>
              </details>
              <details>
                <summary>üî∑ Code Generation Models</summary>
                <div class="math-desc">Programming language modeling, syntax-aware attention</div>
                <ul>
                  <li class="model">GitHub Copilot (OpenAI Codex)</li>
                  <li class="model">CodeT5 / CodeGen</li>
                  <li class="model">StarCoder / Code Llama</li>
                  <li class="model">Replit Code v1.5</li>
                  <li class="model">Amazon CodeWhisperer</li>
                  <li class="model">Tabnine</li>
                  <li class="math-concept">Abstract syntax tree (AST) modeling, code completion probability</li>
                </ul>
              </details>
            </details>

            <!-- Computer Vision -->
            <details>
              <summary>üåø <span class="branch">Computer Vision (CV)</span> <span class="tag">images & video</span></summary>
              <div class="math-desc">Convolutional operations, spatial hierarchies, visual feature learning</div>
              <details>
                <summary>üî∑ Object Detection & Segmentation</summary>
                <div class="math-desc">Non-maximum suppression, intersection over union (IoU), anchor-based/anchor-free methods</div>
                <details>
                  <summary>YOLO Family</summary>
                  <ul>
                    <li class="model">YOLOv1 ‚Üí v3 <span class="tag">early versions</span></li>
                    <li class="model">YOLOv4 / YOLOv5</li>
                    <li class="model">YOLOX / YOLOv6</li>
                    <li class="model">YOLOv8 <span class="tag">ultralytics</span></li>
                    <li class="model">YOLO11 <span class="tag hot">latest</span></li>
                    <li class="math-concept">Grid-based detection, confidence √ó class probability</li>
                  </ul>
                </details>
                <details>
                  <summary>R-CNN Family</summary>
                  <ul>
                    <li class="model">R-CNN</li>
                    <li class="model">Fast R-CNN</li>
                    <li class="model">Faster R-CNN</li>
                    <li class="model">Mask R-CNN <span class="tag">segmentation</span></li>
                    <li class="math-concept">Region proposal networks, ROI pooling/align</li>
                  </ul>
                </details>
                <details>
                  <summary>Modern Detection</summary>
                  <ul>
                    <li class="model">SSD (Single Shot Detector)</li>
                    <li class="model">RetinaNet</li>
                    <li class="math-concept">Focal loss for class imbalance</li>
                    <li class="model">DETR (Detection Transformer)</li>
                    <li class="math-concept">Set prediction, Hungarian matching algorithm</li>
                    <li class="model">EfficientDet</li>
                    <li class="math-concept">Compound scaling, BiFPN architecture</li>
                  </ul>
                </details>
              </details>
              <details>
                <summary>üî∑ Image Classification & Backbones</summary>
                <div class="math-desc">Hierarchical feature extraction, skip connections, batch normalization</div>
                <details>
                  <summary>Convolutional Networks</summary>
                  <ul>
                    <li class="model">LeNet / AlexNet <span class="tag">historical</span></li>
                    <li class="math-concept">Convolution: (f*g)[n] = Œ£f[m]g[n-m]</li>
                    <li class="model">VGG-16 / VGG-19</li>
                    <li class="math-concept">Small 3√ó3 filters, depth over width</li>
                    <li class="model">ResNet (18/34/50/101/152)</li>
                    <li class="math-concept">Residual connections: F(x) + x, gradient highway</li>
                    <li class="model">ResNeXt / Wide ResNet</li>
                    <li class="model">DenseNet</li>
                    <li class="math-concept">Dense connections, feature reuse</li>
                    <li class="model">EfficientNet v1/v2</li>
                    <li class="math-concept">Neural architecture search, compound scaling</li>
                    <li class="model">RegNet</li>
                  </ul>
                </details>
                <details>
                  <summary>Vision Transformers</summary>
                  <div class="math-desc">Patch embeddings, positional encoding, self-attention for vision</div>
                  <ul>
                    <li class="model">Vision Transformer (ViT)</li>
                    <li class="math-concept">Image patches as tokens, position embeddings</li>
                    <li class="model">DeiT (Data-efficient ViT)</li>
                    <li class="math-concept">Distillation token, teacher-student training</li>
                    <li class="model">Swin Transformer</li>
                    <li class="math-concept">Shifted windows, hierarchical feature maps</li>
                    <li class="model">ConvNeXt <span class="tag">modernized ConvNet</span></li>
                    <li class="math-concept">ConvNet with transformer design principles</li>
                    <li class="model">MaxViT</li>
                  </ul>
                </details>
              </details>
              <details>
                <summary>üî∑ Image Generation</summary>
                <details>
                  <summary>Diffusion Models</summary>
                  <div class="math-desc">Forward/reverse diffusion processes, denoising score matching</div>
                  <ul>
                    <li class="model">DDPM / DDIM</li>
                    <li class="math-concept">q(x_t|x‚ÇÄ) = N(‚àöŒ±ÃÖ_t x‚ÇÄ, (1-Œ±ÃÖ_t)I), reverse process</li>
                    <li class="model">Stable Diffusion 1.5 / 2.0</li>
                    <li class="model">Stable Diffusion XL (SDXL)</li>
                    <li class="model">Stable Diffusion 3 <span class="tag hot">latest</span></li>
                    <li class="model">DALL¬∑E 2 / DALL¬∑E 3</li>
                    <li class="model">Midjourney v5 / v6</li>
                    <li class="model">Imagen (Google)</li>
                    <li class="model">Adobe Firefly</li>
                    <li class="math-concept">Latent space diffusion, CLIP guidance, classifier-free guidance</li>
                  </ul>
                </details>
                <details>
                  <summary>GANs & Other Generative</summary>
                  <div class="math-desc">Minimax game theory, adversarial training, Nash equilibrium</div>
                  <ul>
                    <li class="model">StyleGAN 2/3</li>
                    <li class="math-concept">Style injection, AdaIN normalization</li>
                    <li class="model">BigGAN</li>
                    <li class="model">VQ-VAE / VQ-GAN</li>
                    <li class="math-concept">Vector quantization, codebook learning</li>
                    <li class="model">Parti (Google)</li>
                  </ul>
                </details>
              </details>
              <details>
                <summary>üî∑ Video Understanding</summary>
                <div class="math-desc">Spatio-temporal convolutions, temporal modeling, motion estimation</div>
                <ul>
                  <li class="model">Video Swin Transformer</li>
                  <li class="model">TimeSformer</li>
                  <li class="math-concept">Divided space-time attention</li>
                  <li class="model">SlowFast Networks</li>
                  <li class="math-concept">Dual pathway: slow (spatial) + fast (temporal)</li>
                  <li class="model">I3D (Inflated 3D ConvNet)</li>
                  <li class="model">OpenAI Sora <span class="tag hot">video generation</span></li>
                  <li class="model">Runway Gen-2</li>
                  <li class="model">Stable Video Diffusion</li>
                </ul>
              </details>
            </details>

            <!-- Speech / Audio -->
            <details>
              <summary>üåø <span class="branch">Speech & Audio AI</span> <span class="tag">sound processing</span></summary>
              <div class="math-desc">Signal processing, spectrograms, mel-frequency cepstral coefficients (MFCC)</div>
              <details>
                <summary>üî∑ Speech Recognition (ASR)</summary>
                <div class="math-desc">Hidden Markov models, connectionist temporal classification (CTC)</div>
                <ul>
                  <li class="model">Whisper (OpenAI) <span class="tag hot">multilingual</span></li>
                  <li class="math-concept">Sequence-to-sequence with attention</li>
                  <li class="model">Wav2Vec 2.0 (Meta)</li>
                  <li class="math-concept">Contrastive learning on raw audio waveforms</li>
                  <li class="model">DeepSpeech (Mozilla)</li>
                  <li class="math-concept">CTC loss, RNN-based architecture</li>
                  <li class="model">Conformer</li>
                  <li class="math-concept">Convolution + transformer hybrid</li>
                  <li class="model">Google Speech-to-Text</li>
                  <li class="model">Amazon Transcribe</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Text-to-Speech (TTS)</summary>
                <div class="math-desc">Vocoder design, mel-spectrogram prediction, neural audio synthesis</div>
                <ul>
                  <li class="model">Tacotron 2</li>
                  <li class="math-concept">Encoder-decoder with attention, mel-spectrogram prediction</li>
                  <li class="model">WaveNet / WaveGlow</li>
                  <li class="math-concept">Dilated causal convolutions, autoregressive generation</li>
                  <li class="model">VITS (End-to-end TTS)</li>
                  <li class="math-concept">Variational inference, normalizing flows</li>
                  <li class="model">Bark (Suno AI) <span class="tag">expressive</span></li>
                  <li class="model">ElevenLabs <span class="tag hot">commercial</span></li>
                  <li class="model">Tortoise TTS</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Music & Audio Generation</summary>
                <div class="math-desc">Audio synthesis, harmonic analysis, rhythm modeling</div>
                <ul>
                  <li class="model">MusicLM (Google)</li>
                  <li class="model">Suno AI <span class="tag hot">commercial</span></li>
                  <li class="model">Udio <span class="tag hot">commercial</span></li>
                  <li class="model">Jukebox (OpenAI)</li>
                  <li class="math-concept">VQ-VAE hierarchical modeling</li>
                  <li class="model">AudioCraft (Meta)</li>
                  <li class="model">MusiCNN</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Audio Processing</summary>
                <ul>
                  <li class="model">PANNs (Audio Tagging)</li>
                  <li class="model">YAMNet (Audio Event Detection)</li>
                  <li class="model">AudioMAE</li>
                  <li class="math-concept">Masked autoencoding for audio spectrograms</li>
                </ul>
              </details>
            </details>

            <!-- Multimodal -->
            <details>
              <summary>üåø <span class="branch">Multimodal AI</span> <span class="tag hot">text + image + audio + video</span></summary>
              <div class="math-desc">Cross-modal attention, contrastive learning, unified embedding spaces</div>
              <details>
                <summary>üî∑ Vision-Language Models</summary>
                <div class="math-desc">Cross-attention between visual and textual features</div>
                <ul>
                  <li class="model">GPT‚Äë4o / GPT‚Äë4‚Äëvision <span class="tag hot">OpenAI</span></li>
                  <li class="model">Claude 3 Opus/Sonnet (vision)</li>
                  <li class="model">Gemini Pro Vision / Ultra</li>
                  <li class="model">LLaVA (Large Language and Vision)</li>
                  <li class="math-concept">Visual instruction tuning, cross-modal alignment</li>
                  <li class="model">BLIP / BLIP-2</li>
                  <li class="math-concept">Bootstrap vision-language pre-training</li>
                  <li class="model">Flamingo (DeepMind)</li>
                  <li class="math-concept">Few-shot learning with frozen language models</li>
                  <li class="model">Kosmos‚Äë1/2 (Microsoft)</li>
                  <li class="model">Qwen-VL</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ CLIP & Embedding Models</summary>
                <div class="math-desc">Contrastive learning: maximize similarity of correct pairs, minimize incorrect pairs</div>
                <ul>
                  <li class="model">CLIP (OpenAI)</li>
                  <li class="math-concept">Contrastive loss: L = -log(exp(sim(x,y)/œÑ) / Œ£exp(sim(x,y')/œÑ))</li>
                  <li class="model">ALIGN (Google)</li>
                  <li class="model">CoCa (Contrastive Captioners)</li>
                  <li class="model">SigLIP</li>
                  <li class="math-concept">Sigmoid loss instead of softmax for efficiency</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Multimodal Generation</summary>
                <ul>
                  <li class="model">GPT-4o <span class="tag hot">text‚Üíimage‚Üítext</span></li>
                  <li class="model">Gemini 2.0 <span class="tag hot">comprehensive</span></li>
                  <li class="model">Any-to-Any (Meta) <span class="tag emerging">research</span></li>
                  <li class="math-concept">Unified tokenization across modalities</li>
                </ul>
              </details>
            </details>

            <!-- Robotics -->
            <details>
              <summary>üåø <span class="branch">Robotics & Embodied AI</span> <span class="tag">physical world</span></summary>
              <div class="math-desc">Control theory, kinematics, dynamics, trajectory optimization</div>
              <details>
                <summary>üî∑ Manipulation & Control</summary>
                <div class="math-desc">Inverse kinematics, PID control, Model Predictive Control (MPC)</div>
                <ul>
                  <li class="model">RT-1 / RT-2 (Google)</li>
                  <li class="math-concept">Transformer for robotics, vision-language-action</li>
                  <li class="model">PaLM-E <span class="tag">language + robotics</span></li>
                  <li class="model">RoboCat (DeepMind)</li>
                  <li class="model">OpenVLA <span class="tag emerging">vision-language-action</span></li>
                  <li class="model">SARA (Stanford)</li>
                  <li class="math-concept">Spatial action representations</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Simulation & Training</summary>
                <div class="math-desc">Physics simulation, contact dynamics, domain randomization</div>
                <ul>
                  <li class="model">Isaac Gym (NVIDIA)</li>
                  <li class="model">MuJoCo</li>
                  <li class="math-concept">Multi-joint dynamics with contact</li>
                  <li class="model">PyBullet</li>
                  <li class="model">Habitat (Meta)</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Navigation & SLAM</summary>
                <div class="math-desc">Simultaneous Localization and Mapping, particle filters, graph optimization</div>
                <ul>
                  <li class="model">Neural SLAM</li>
                  <li class="model">PointNet++</li>
                  <li class="math-concept">Hierarchical point set feature learning</li>
                  <li class="model">DD-PPO (Distributed RL)</li>
                </ul>
              </details>
            </details>

            <!-- Reinforcement Learning -->
            <details>
              <summary>üåø <span class="branch">Reinforcement Learning (RL)</span> <span class="tag">decision making</span></summary>
              <div class="math-desc">Markov Decision Processes, Bellman equations, policy gradients, temporal difference learning</div>
              <details>
                <summary>üî∑ Game Playing</summary>
                <div class="math-desc">Monte Carlo Tree Search, value/policy networks, self-play</div>
                <ul>
                  <li class="model">AlphaGo / AlphaZero</li>
                  <li class="math-concept">MCTS + neural networks, UCB1 selection</li>
                  <li class="model">MuZero</li>
                  <li class="math-concept">Model-based planning with learned dynamics</li>
                  <li class="model">OpenAI Five (Dota 2)</li>
                  <li class="model">AlphaStar (StarCraft II)</li>
                  <li class="model">Agent57 (Atari)</li>
                  <li class="math-concept">Meta-controller for exploration vs exploitation</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ RLHF & Alignment</summary>
                <div class="desc">Human feedback training for AI alignment and safety.</div>
                <div class="math-desc">Preference modeling, reward learning from comparisons, KL regularization</div>
                <ul>
                  <li class="model">InstructGPT (OpenAI)</li>
                  <li class="math-concept">PPO with KL penalty: J = E[r(x,y)] - Œ≤ KL(œÄ,œÄ_ref)</li>
                  <li class="model">Constitutional AI (Anthropic)</li>
                  <li class="model">Sparrow (DeepMind)</li>
                  <li class="model">LaMDA Safety Training</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Policy Learning</summary>
                <div class="math-desc">Policy gradient methods, actor-critic algorithms, experience replay</div>
                <ul>
                  <li class="model">PPO (Proximal Policy Optimization)</li>
                  <li class="math-concept">Clipped surrogate objective, trust region</li>
                  <li class="model">SAC (Soft Actor-Critic)</li>
                  <li class="math-concept">Maximum entropy RL, entropy regularization</li>
                  <li class="model">Rainbow DQN</li>
                  <li class="math-concept">Combines 6 DQN improvements</li>
                  <li class="model">IMPALA</li>
                </ul>
              </details>
            </details>

            <!-- Continue with remaining sections... -->
            <details>
              <summary>üåø <span class="branch">Recommendation Systems</span> <span class="tag">personalization</span></summary>
              <div class="math-desc">Collaborative filtering, matrix factorization, embedding learning</div>
              <details>
                <summary>üî∑ Deep Recommenders</summary>
                <div class="math-desc">Neural collaborative filtering, factorization machines, deep CTR prediction</div>
                <ul>
                  <li class="model">Neural Collaborative Filtering</li>
                  <li class="math-concept">Replace inner product with neural networks</li>
                  <li class="model">Wide & Deep (Google)</li>
                  <li class="math-concept">Memorization (wide) + generalization (deep)</li>
                  <li class="model">DeepFM</li>
                  <li class="math-concept">Factorization machines + deep neural networks</li>
                  <li class="model">DIN / DIEN (Alibaba)</li>
                  <li class="math-concept">Attention-based user interest modeling</li>
                  <li class="model">PinSage (Pinterest)</li>
                  <li class="math-concept">Graph convolutional networks for recommendations</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Sequential Recommendations</summary>
                <div class="math-desc">Sequence modeling, temporal dynamics, session-based recommendations</div>
                <ul>
                  <li class="model">SASRec (Self-Attention)</li>
                  <li class="math-concept">Self-attention for sequential patterns</li>
                  <li class="model">BERT4Rec</li>
                  <li class="math-concept">Bidirectional encoder for user sequences</li>
                  <li class="model">GRU4Rec</li>
                  <li class="math-concept">RNN for session-based recommendations</li>
                </ul>
              </details>
            </details>

            <!-- Drug Discovery & Science -->
            <details>
              <summary>üåø <span class="branch">AI for Science & Drug Discovery</span> <span class="tag emerging">scientific AI</span></summary>
              <div class="math-desc">Molecular dynamics, protein folding energy landscapes, sequence-structure relationships</div>
              <details>
                <summary>üî∑ Protein Folding & Structure</summary>
                <div class="math-desc">Energy minimization, Ramachandran plots, contact prediction, attention over residue pairs</div>
                <ul>
                  <li class="model">AlphaFold 2/3 (DeepMind) <span class="tag hot">breakthrough</span></li>
                  <li class="math-concept">MSA processing, attention over residue pairs, distance/angle prediction</li>
                  <li class="model">ESMFold (Meta)</li>
                  <li class="math-concept">Language model embeddings for folding</li>
                  <li class="model">ChimeraX AlphaFold</li>
                  <li class="model">ColabFold</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Drug Discovery</summary>
                <div class="math-desc">Molecular representations, SMILES encoding, molecular property prediction</div>
                <ul>
                  <li class="model">AlphaFold DB</li>
                  <li class="model">MolGAN</li>
                  <li class="math-concept">GANs for molecular generation</li>
                  <li class="model">Junction Tree VAE</li>
                  <li class="math-concept">Tree-structured molecular representations</li>
                  <li class="model">ChemBERTa</li>
                  <li class="model">MegaMolBART</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Materials Science</summary>
                <ul>
                  <li class="model">Crystal Graph Neural Networks</li>
                  <li class="math-concept">Crystal structure as graphs, material property prediction</li>
                  <li class="model">SchNet</li>
                  <li class="math-concept">Continuous-filter convolutional networks</li>
                  <li class="model">Materials Project ML</li>
                </ul>
              </details>
            </details>

            <!-- Autonomous Systems -->
            <details>
              <summary>üåø <span class="branch">Autonomous Systems</span> <span class="tag">self-driving</span></summary>
              <div class="math-desc">Sensor fusion, localization, path planning, control theory</div>
              <details>
                <summary>üî∑ Self-Driving Cars</summary>
                <div class="math-desc">SLAM, Kalman filtering, trajectory optimization, behavioral planning</div>
                <ul>
                  <li class="model">Tesla FSD (Full Self-Driving)</li>
                  <li class="math-concept">Neural network end-to-end driving</li>
                  <li class="model">Waymo Driver</li>
                  <li class="model">Cruise AV</li>
                  <li class="model">Mobileye EyeQ</li>
                  <li class="model">NVIDIA DRIVE</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Perception Systems</summary>
                <div class="math-desc">3D object detection, bird's eye view representations, multi-sensor fusion</div>
                <ul>
                  <li class="model">BEVFormer (Bird's Eye View)</li>
                  <li class="math-concept">Spatial cross-attention, temporal self-attention</li>
                  <li class="model">DETR3D</li>
                  <li class="model">PointPillars</li>
                  <li class="math-concept">Point cloud to pseudo-image conversion</li>
                  <li class="model">CenterPoint</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Drones & UAVs</summary>
                <ul>
                  <li class="model">DJI AI Flight Control</li>
                  <li class="model">AirSim (Microsoft)</li>
                  <li class="model">FlightGoggles</li>
                  <li class="math-concept">Real-time trajectory optimization, collision avoidance</li>
                </ul>
              </details>
            </details>

            <!-- Time Series & Forecasting -->
            <details>
              <summary>üåø <span class="branch">Time Series & Forecasting</span> <span class="tag">temporal data</span></summary>
              <div class="math-desc">Autoregressive models, state space models, spectral analysis, trend decomposition</div>
              <details>
                <summary>üî∑ Deep Time Series Models</summary>
                <div class="math-desc">Recurrent architectures, temporal convolutions, attention over time</div>
                <ul>
                  <li class="model">LSTM / GRU</li>
                  <li class="math-concept">Gating mechanisms, forget gates, cell state updates</li>
                  <li class="model">Temporal Convolutional Networks</li>
                  <li class="math-concept">Dilated convolutions, causal convolutions</li>
                  <li class="model">Transformer for Time Series</li>
                  <li class="math-concept">Positional encoding for temporal patterns</li>
                  <li class="model">N-BEATS</li>
                  <li class="math-concept">Neural basis expansion analysis, interpretable forecasting</li>
                  <li class="model">DeepAR (Amazon)</li>
                  <li class="math-concept">Autoregressive RNN with probabilistic forecasting</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Foundation Models for Forecasting</summary>
                <div class="math-desc">Pre-trained models on diverse time series, zero-shot forecasting</div>
                <ul>
                  <li class="model">TimeGPT <span class="tag emerging">Nixtla</span></li>
                  <li class="math-concept">Transformer pre-trained on 100B+ time series points</li>
                  <li class="model">Chronos (Amazon) <span class="tag emerging">zero-shot</span></li>
                  <li class="math-concept">Tokenized time series, language model scaling laws</li>
                  <li class="model">ForecastPFN</li>
                  <li class="math-concept">Prior-data fitted networks, in-context learning</li>
                </ul>
              </details>
            </details>

            <!-- Graph Neural Networks -->
            <details>
              <summary>üåø <span class="branch">Graph Neural Networks</span> <span class="tag">structured data</span></summary>
              <div class="math-desc">Message passing, graph convolutions, spectral graph theory, adjacency matrices</div>
              <details>
                <summary>üî∑ Core GNN Architectures</summary>
                <div class="math-desc">Neighborhood aggregation, permutation invariance, graph isomorphism</div>
                <ul>
                  <li class="model">Graph Convolutional Networks (GCN)</li>
                  <li class="math-concept">H^(l+1) = œÉ(D^(-1/2)AD^(-1/2)H^(l)W^(l)), spectral approach</li>
                  <li class="model">GraphSAGE</li>
                  <li class="math-concept">Inductive learning, sampling and aggregating</li>
                  <li class="model">Graph Attention Networks (GAT)</li>
                  <li class="math-concept">Self-attention over graph neighborhoods</li>
                  <li class="model">Graph Transformer</li>
                  <li class="math-concept">Global attention with positional encodings</li>
                  <li class="model">Message Passing Neural Networks</li>
                  <li class="math-concept">m_ij = M(h_i, h_j, e_ij), h_i' = U(h_i, Œ£ m_ij)</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Applications</summary>
                <ul>
                  <li class="model">Social Network Analysis</li>
                  <li class="model">Knowledge Graph Reasoning</li>
                  <li class="model">Molecular Property Prediction</li>
                  <li class="model">Traffic Flow Prediction</li>
                  <li class="math-concept">Spatio-temporal graph modeling</li>
                </ul>
              </details>
            </details>

            <!-- AI Agents -->
            <details>
              <summary>üåø <span class="branch">AI Agents & Planning</span> <span class="tag hot">autonomous agents</span></summary>
              <div class="math-desc">Planning algorithms, state space search, multi-agent coordination, game theory</div>
              <details>
                <summary>üî∑ LLM-based Agents</summary>
                <div class="math-desc">Reasoning chains, tool usage, action space modeling</div>
                <ul>
                  <li class="model">AutoGPT <span class="tag">autonomous</span></li>
                  <li class="model">LangChain Agents</li>
                  <li class="model">ReAct (Reasoning + Acting)</li>
                  <li class="math-concept">Thought-action-observation loops</li>
                  <li class="model">Toolformer</li>
                  <li class="math-concept">Self-supervised tool use learning</li>
                  <li class="model">WebGPT</li>
                  <li class="model">Code Interpreter (OpenAI)</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Multi-Agent Systems</summary>
                <div class="math-desc">Cooperative game theory, Nash equilibrium, mechanism design</div>
                <ul>
                  <li class="model">AutoGen (Microsoft) <span class="tag hot">multi-agent</span></li>
                  <li class="model">CrewAI</li>
                  <li class="model">MetaGPT</li>
                  <li class="model">ChatDev</li>
                  <li class="math-concept">Role assignment, communication protocols</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ AI Workflow & Automation Platforms</summary>
                <div class="desc">No-code/low-code platforms for building AI-powered workflows and automations.</div>
                <div class="math-desc">Directed acyclic graphs (DAGs), workflow orchestration, event-driven systems</div>
                <details>
                  <summary>AI-First Platforms</summary>
                  <ul>
                    <li class="model">Dify <span class="tag hot">LLM app builder</span></li>
                    <li class="model">Flowise <span class="tag">drag-and-drop LLM</span></li>
                    <li class="model">LangFlow <span class="tag">visual LangChain</span></li>
                    <li class="model">Botpress <span class="tag">conversational AI</span></li>
                    <li class="model">Rasa <span class="tag">open source chatbot</span></li>
                    <li class="model">Voiceflow <span class="tag">voice/chat apps</span></li>
                  </ul>
                </details>
                <details>
                  <summary>General Automation + AI</summary>
                  <ul>
                    <li class="model">Make (formerly Integromat) <span class="tag hot">visual automation</span></li>
                    <li class="model">n8n <span class="tag">open source workflow</span></li>
                    <li class="model">Zapier <span class="tag">app integration</span></li>
                    <li class="model">Microsoft Power Automate</li>
                    <li class="model">IFTTT <span class="tag">simple triggers</span></li>
                    <li class="model">Activepieces <span class="tag">open source</span></li>
                    <li class="model">Windmill <span class="tag">developer-first</span></li>
                  </ul>
                </details>
                <details>
                  <summary>Agent Orchestration</summary>
                  <ul>
                    <li class="model">MCP (Model Context Protocol) <span class="tag hot">Anthropic standard</span></li>
                    <li class="model">OpenAI Assistants API</li>
                    <li class="model">LangGraph <span class="tag">stateful agents</span></li>
                    <li class="math-concept">State machines, graph-based agent workflows</li>
                    <li class="model">Semantic Kernel (Microsoft)</li>
                    <li class="model">Haystack <span class="tag">deepset</span></li>
                    <li class="model">Crew AI Studio</li>
                  </ul>
                </details>
                <details>
                  <summary>Enterprise AI Orchestration</summary>
                  <ul>
                    <li class="model">Databricks MLflow</li>
                    <li class="model">Kubeflow Pipelines</li>
                    <li class="model">Azure ML Pipelines</li>
                    <li class="model">AWS Step Functions</li>
                    <li class="model">Google Cloud Workflows</li>
                    <li class="model">Prefect <span class="tag">data workflows</span></li>
                    <li class="model">Airflow <span class="tag">Apache</span></li>
                    <li class="math-concept">DAG scheduling, dependency management</li>
                  </ul>
                </details>
              </details>
              <details>
                <summary>üî∑ Planning & Reasoning</summary>
                <div class="math-desc">Search algorithms, constraint satisfaction, logical inference</div>
                <ul>
                  <li class="model">Tree of Thoughts</li>
                  <li class="math-concept">Breadth-first search over reasoning trees</li>
                  <li class="model">Chain-of-Thought Prompting</li>
                  <li class="math-concept">Step-by-step reasoning decomposition</li>
                  <li class="model">Self-Consistency Decoding</li>
                  <li class="math-concept">Sample multiple reasoning paths, majority vote</li>
                  <li class="model">Program-aided Language Models</li>
                  <li class="math-concept">Code generation for numerical reasoning</li>
                </ul>
              </details>
            </details>

            <!-- Generative AI -->
            <details>
              <summary>üåø <span class="branch">Generative AI Architectures</span> <span class="tag">creation</span></summary>
              <div class="math-desc">Probabilistic modeling, likelihood maximization, latent variable models</div>
              <details>
                <summary>üî∑ Transformer Architectures</summary>
                <div class="math-desc">Self-attention: Attention(Q,K,V) = softmax(QK^T/‚àöd_k)V, positional encoding</div>
                <ul>
                  <li class="model">Vanilla Transformer</li>
                  <li class="math-concept">Multi-head attention, feed-forward networks</li>
                  <li class="model">GPT (Decoder-only)</li>
                  <li class="math-concept">Causal masking, autoregressive generation</li>
                  <li class="model">BERT (Encoder-only)</li>
                  <li class="math-concept">Bidirectional attention, masked language modeling</li>
                  <li class="model">T5 (Encoder-Decoder)</li>
                  <li class="math-concept">Text-to-text unified framework</li>
                  <li class="model">PaLM (Pathways)</li>
                  <li class="model">Switch Transformer</li>
                  <li class="math-concept">Mixture of experts routing</li>
                  <li class="model">Mamba <span class="tag emerging">state space</span></li>
                  <li class="math-concept">Selective state spaces, linear attention alternative</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Diffusion Models</summary>
                <div class="math-desc">Forward process: q(x_t|x_{t-1}) = N(‚àö(1-Œ≤_t)x_{t-1}, Œ≤_t I), reverse denoising</div>
                <ul>
                  <li class="model">DDPM (Denoising Diffusion)</li>
                  <li class="math-concept">Markov chain diffusion, score matching</li>
                  <li class="model">Stable Diffusion</li>
                  <li class="model">DALL¬∑E 2/3</li>
                  <li class="model">Imagen / Parti</li>
                  <li class="model">ControlNet <span class="tag">controllable generation</span></li>
                  <li class="math-concept">Conditional generation with spatial controls</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Variational Models</summary>
                <div class="math-desc">Evidence Lower BOund (ELBO), KL divergence regularization</div>
                <ul>
                  <li class="model">VAE (Variational Autoencoder)</li>
                  <li class="math-concept">ELBO = E[log p(x|z)] - KL(q(z|x)||p(z))</li>
                  <li class="model">Œ≤-VAE</li>
                  <li class="math-concept">Œ≤-weighted KL term for disentanglement</li>
                  <li class="model">VQ-VAE / VQ-VAE-2</li>
                  <li class="math-concept">Vector quantization, discrete latent space</li>
                </ul>
              </details>
            </details>

            <!-- AI Safety & Alignment -->
            <details>
              <summary>üåø <span class="branch">AI Safety & Alignment</span> <span class="tag emerging">responsible AI</span></summary>
              <div class="math-desc">Robustness optimization, distributional shift, adversarial examples, reward modeling</div>
              <details>
                <summary>üî∑ Alignment Techniques</summary>
                <div class="math-desc">Human preference modeling, reward learning, value alignment</div>
                <ul>
                  <li class="model">RLHF (Reinforcement Learning from Human Feedback)</li>
                  <li class="math-concept">Bradley-Terry preference model, reward model training</li>
                  <li class="model">Constitutional AI (Anthropic)</li>
                  <li class="math-concept">Self-supervised harmfulness reduction</li>
                  <li class="model">AI Safety via Debate</li>
                  <li class="math-concept">Two-player zero-sum game for truthfulness</li>
                  <li class="model">Iterated Amplification</li>
                  <li class="model">Red Teaming Methods</li>
                  <li class="math-concept">Adversarial testing, failure mode discovery</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Interpretability & Explainability</summary>
                <div class="math-desc">Attribution methods, gradient-based explanations, feature importance</div>
                <ul>
                  <li class="model">LIME / SHAP</li>
                  <li class="math-concept">Local linear approximations, Shapley values</li>
                  <li class="model">Attention Visualization</li>
                  <li class="model">Concept Activation Vectors</li>
                  <li class="math-concept">TCAV: directional derivatives in concept space</li>
                  <li class="model">Mechanistic Interpretability</li>
                  <li class="model">Anthropic's Circuit Analysis</li>
                  <li class="math-concept">Reverse engineering neural network computations</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Robustness & Security</summary>
                <div class="math-desc">Adversarial perturbations, certified defenses, distributional robustness</div>
                <ul>
                  <li class="model">Adversarial Training</li>
                  <li class="math-concept">Minimax optimization, PGD attacks</li>
                  <li class="model">Certified Defenses</li>
                  <li class="math-concept">Lipschitz constraints, interval bound propagation</li>
                  <li class="model">Differential Privacy</li>
                  <li class="math-concept">Œµ-differential privacy, noise injection</li>
                  <li class="model">Federated Learning</li>
                  <li class="math-concept">Distributed learning, privacy preservation</li>
                </ul>
              </details>
            </details>

            <!-- Edge AI & Optimization -->
            <details>
              <summary>üåø <span class="branch">Edge AI & Model Optimization</span> <span class="tag">efficiency</span></summary>
              <div class="math-desc">Model compression, quantization, pruning, efficient architectures</div>
              <details>
                <summary>üî∑ Model Compression</summary>
                <div class="math-desc">Singular value decomposition, weight magnitude pruning, entropy-based quantization</div>
                <ul>
                  <li class="model">Knowledge Distillation</li>
                  <li class="math-concept">Student mimics teacher: L = Œ±L_CE + (1-Œ±)L_KD</li>
                  <li class="model">Pruning (Magnitude/Structured)</li>
                  <li class="math-concept">Weight magnitude thresholding, lottery ticket hypothesis</li>
                  <li class="model">Quantization (INT8/INT4)</li>
                  <li class="math-concept">Uniform/non-uniform quantization, calibration datasets</li>
                  <li class="model">Low-Rank Factorization</li>
                  <li class="math-concept">Matrix decomposition: W ‚âà UV^T</li>
                  <li class="model">LoRA (Low-Rank Adaptation)</li>
                  <li class="math-concept">W = W‚ÇÄ + BA, where B‚ààR^(d√ór), A‚ààR^(r√ók)</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Mobile & Edge Models</summary>
                <div class="math-desc">Depthwise separable convolutions, neural architecture search</div>
                <ul>
                  <li class="model">MobileNet v1/v2/v3</li>
                  <li class="math-concept">Depthwise separable convolutions, inverted residuals</li>
                  <li class="model">EfficientNet</li>
                  <li class="math-concept">Compound scaling: depth/width/resolution</li>
                  <li class="model">TinyBERT</li>
                  <li class="model">DistilBERT</li>
                  <li class="model">TensorFlow Lite</li>
                  <li class="model">ONNX Runtime</li>
                  <li class="model">Apple Core ML</li>
                </ul>
              </details>
            </details>

            <!-- Specialized Domains -->
            <details>
              <summary>üåø <span class="branch">Domain-Specific AI</span> <span class="tag">specialized applications</span></summary>
              <div class="math-desc">Domain adaptation, transfer learning, specialized loss functions</div>
              <details>
                <summary>üî∑ Healthcare & Medical AI</summary>
                <div class="math-desc">Medical image analysis, diagnostic classification, survival analysis</div>
                <ul>
                  <li class="model">Med-PaLM (Google)</li>
                  <li class="model">GPT-4 Medical</li>
                  <li class="model">CheXNet (Chest X-ray)</li>
                  <li class="math-concept">DenseNet for radiological diagnosis</li>
                  <li class="model">DeepMind AlphaFold</li>
                  <li class="model">IBM Watson Health</li>
                  <li class="model">Radiology AI (Various)</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Finance & Trading</summary>
                <div class="math-desc">Time series forecasting, risk modeling, portfolio optimization</div>
                <ul>
                  <li class="model">BloombergGPT</li>
                  <li class="model">FinBERT</li>
                  <li class="model">Algorithmic Trading AI</li>
                  <li class="math-concept">Market microstructure modeling, order flow prediction</li>
                  <li class="model">Risk Management Models</li>
                  <li class="math-concept">Value at Risk (VaR), Monte Carlo simulations</li>
                  <li class="model">Fraud Detection Systems</li>
                  <li class="math-concept">Anomaly detection, graph-based fraud networks</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Legal AI</summary>
                <ul>
                  <li class="model">Legal BERT variants</li>
                  <li class="model">Contract Analysis AI</li>
                  <li class="model">Case Law Search</li>
                  <li class="model">Patent Analysis</li>
                  <li class="math-concept">Legal document similarity, citation networks</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Education & Learning</summary>
                <div class="math-desc">Adaptive learning, knowledge tracing, educational data mining</div>
                <ul>
                  <li class="model">Khan Academy AI Tutor</li>
                  <li class="model">Duolingo AI</li>
                  <li class="math-concept">Spaced repetition algorithms, forgetting curves</li>
                  <li class="model">Adaptive Learning Systems</li>
                  <li class="math-concept">Bayesian knowledge tracing, item response theory</li>
                  <li class="model">Academic Writing Assistants</li>
                </ul>
              </details>
            </details>

            <!-- Quantum AI -->
            <details>
              <summary>üåø <span class="branch">Quantum AI & Computing</span> <span class="tag emerging">quantum advantage</span></summary>
              <div class="math-desc">Quantum superposition, entanglement, quantum circuit learning, variational quantum algorithms</div>
              <details>
                <summary>üî∑ Quantum Machine Learning (QML)</summary>
                <div class="math-desc">Quantum feature maps, parameterized quantum circuits, quantum kernels</div>
                <ul>
                  <li class="model">Variational Quantum Circuits (VQC)</li>
                  <li class="math-concept">U(Œ∏) = ‚àèU_i(Œ∏_i), parameterized quantum gates</li>
                  <li class="model">Quantum Neural Networks</li>
                  <li class="math-concept">Quantum perceptrons, quantum backpropagation</li>
                  <li class="model">Quantum Support Vector Machines</li>
                  <li class="math-concept">Quantum feature maps, exponential kernel spaces</li>
                  <li class="model">Quantum Generative Models</li>
                  <li class="math-concept">Born machine, quantum GANs</li>
                  <li class="model">IBM Qiskit Machine Learning</li>
                  <li class="model">Google Cirq TensorFlow Quantum</li>
                  <li class="model">PennyLane (Xanadu)</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Quantum Algorithms</summary>
                <div class="math-desc">Grover's algorithm, quantum Fourier transform, amplitude amplification</div>
                <ul>
                  <li class="model">Variational Quantum Eigensolver (VQE)</li>
                  <li class="math-concept">‚ü®œà(Œ∏)|H|œà(Œ∏)‚ü© minimization, NISQ algorithms</li>
                  <li class="model">Quantum Approximate Optimization (QAOA)</li>
                  <li class="math-concept">Alternating ansatz: e^(-iŒ≥H_C)e^(-iŒ≤H_M)</li>
                  <li class="model">Quantum Principal Component Analysis</li>
                  <li class="math-concept">Quantum matrix exponentiation, HHL algorithm</li>
                  <li class="model">D-Wave Quantum Annealing</li>
                  <li class="math-concept">Ising model optimization, quantum tunneling</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Hybrid Quantum-Classical</summary>
                <div class="math-desc">Variational hybrid algorithms, classical optimization of quantum circuits</div>
                <ul>
                  <li class="model">Quantum-Classical Neural Networks</li>
                  <li class="model">Quantum Transfer Learning</li>
                  <li class="math-concept">Pre-trained quantum feature extractors</li>
                  <li class="model">Quantum Reinforcement Learning</li>
                  <li class="math-concept">Quantum policy gradients, quantum Q-learning</li>
                  <li class="model">Quantum Federated Learning</li>
                </ul>
              </details>
            </details>

            <!-- Federated & Distributed Learning -->
            <details>
              <summary>üåø <span class="branch">Federated & Distributed Learning</span> <span class="tag hot">privacy-preserving</span></summary>
              <div class="math-desc">Distributed optimization, privacy preservation, secure aggregation, communication efficiency</div>
              <details>
                <summary>üî∑ Federated Learning Algorithms</summary>
                <div class="math-desc">Federated averaging, non-IID data challenges, client sampling strategies</div>
                <ul>
                  <li class="model">FedAvg (Federated Averaging)</li>
                  <li class="math-concept">w^{t+1} = w^t - Œ∑‚àáF(w^t), F = Œ£p_kF_k(w)</li>
                  <li class="model">FedProx (Federated Proximal)</li>
                  <li class="math-concept">Proximal term: Œº/2||w-w^t||¬≤, heterogeneity handling</li>
                  <li class="model">FedNova (Federated Nova)</li>
                  <li class="math-concept">Normalized averaging, varying local steps</li>
                  <li class="model">SCAFFOLD</li>
                  <li class="math-concept">Control variates for client drift correction</li>
                  <li class="model">FedOpt (Adam/AdaGrad variants)</li>
                  <li class="math-concept">Server-side adaptive optimization</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Split & Vertical Learning</summary>
                <div class="math-desc">Model splitting, gradient compression, vertical data partitioning</div>
                <ul>
                  <li class="model">Split Learning</li>
                  <li class="math-concept">Forward pass splitting, smashed data transmission</li>
                  <li class="model">Vertical Federated Learning</li>
                  <li class="math-concept">Feature space partitioning, secure computation</li>
                  <li class="model">SplitFed (Split + Federated)</li>
                  <li class="model">Gradient Compression</li>
                  <li class="math-concept">Sparsification, quantization, error feedback</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Privacy & Security</summary>
                <div class="math-desc">Differential privacy, secure aggregation, homomorphic encryption</div>
                <ul>
                  <li class="model">Differential Privacy in FL</li>
                  <li class="math-concept">DP-SGD: noise œÉ = C‚àö(2ln(1.25/Œ¥))/Œµ</li>
                  <li class="model">Secure Multiparty Computation</li>
                  <li class="math-concept">Secret sharing, garbled circuits</li>
                  <li class="model">Byzantine-Robust Aggregation</li>
                  <li class="math-concept">Krum, trimmed mean, geometric median</li>
                  <li class="model">Homomorphic Encryption</li>
                  <li class="math-concept">Computing on encrypted data, CKKS scheme</li>
                </ul>
              </details>
            </details>

            <!-- MLOps & Infrastructure -->
            <details>
              <summary>üåø <span class="branch">AI Infrastructure & MLOps</span> <span class="tag">production systems</span></summary>
              <div class="math-desc">Continuous integration/deployment, model monitoring, A/B testing, drift detection</div>
              <details>
                <summary>üî∑ Model Deployment & Serving</summary>
                <div class="math-desc">Load balancing, auto-scaling, latency optimization, resource allocation</div>
                <ul>
                  <li class="model">Hugging Face Inference Endpoints</li>
                  <li class="model">Replicate Cloud Platform</li>
                  <li class="model">AWS SageMaker Endpoints</li>
                  <li class="model">Google Vertex AI</li>
                  <li class="model">Azure ML Endpoints</li>
                  <li class="model">Seldon Core</li>
                  <li class="model">KServe (Kubernetes)</li>
                  <li class="model">TensorFlow Serving</li>
                  <li class="model">TorchServe</li>
                  <li class="model">ONNX Runtime Server</li>
                  <li class="math-concept">Request batching, model caching, GPU utilization</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Monitoring & Observability</summary>
                <div class="math-desc">Statistical drift detection, performance monitoring, alert systems</div>
                <ul>
                  <li class="model">Weights & Biases</li>
                  <li class="model">MLflow Tracking</li>
                  <li class="model">Neptune AI</li>
                  <li class="model">ClearML</li>
                  <li class="model">Evidently AI <span class="tag">drift detection</span></li>
                  <li class="math-concept">KL divergence drift: D_KL(P_ref||P_curr)</li>
                  <li class="model">Arize AI</li>
                  <li class="model">Fiddler AI</li>
                  <li class="model">WhyLabs</li>
                  <li class="math-concept">Population stability index, data quality metrics</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Feature Engineering & Storage</summary>
                <div class="math-desc">Feature pipelines, versioning, real-time serving, consistency</div>
                <ul>
                  <li class="model">Feast (Feature Store)</li>
                  <li class="model">Tecton</li>
                  <li class="model">Hopsworks</li>
                  <li class="model">AWS Feature Store</li>
                  <li class="model">Databricks Feature Store</li>
                  <li class="model">DVC (Data Version Control)</li>
                  <li class="model">Great Expectations</li>
                  <li class="math-concept">Feature consistency, point-in-time correctness</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ A/B Testing & Experimentation</summary>
                <div class="math-desc">Statistical significance, power analysis, multi-armed bandits</div>
                <ul>
                  <li class="model">Optimizely</li>
                  <li class="model">LaunchDarkly</li>
                  <li class="model">Split.io</li>
                  <li class="model">Google Optimize</li>
                  <li class="model">Facebook Planout</li>
                  <li class="math-concept">Welch's t-test, sequential testing, false discovery rate</li>
                  <li class="model">Multi-Armed Bandits</li>
                  <li class="math-concept">Thompson sampling, upper confidence bounds</li>
                </ul>
              </details>
            </details>

            <!-- Retrieval-Augmented Generation -->
            <details>
              <summary>üåø <span class="branch">Retrieval-Augmented Generation (RAG)</span> <span class="tag hot">knowledge integration</span></summary>
              <div class="math-desc">Dense retrieval, vector similarity, knowledge fusion, query decomposition</div>
              <details>
                <summary>üî∑ Dense Retrieval Systems</summary>
                <div class="math-desc">Bi-encoder architecture, contrastive learning, hard negative mining</div>
                <ul>
                  <li class="model">DPR (Dense Passage Retrieval)</li>
                  <li class="math-concept">Similarity: sim(q,p) = E_Q(q)^T E_P(p)</li>
                  <li class="model">ColBERT</li>
                  <li class="math-concept">Late interaction: Œ£ max_j E_q_i^T E_p_j</li>
                  <li class="model">ANCE (Approximate Nearest Neighbor)</li>
                  <li class="model">RetroMAE</li>
                  <li class="math-concept">Masked autoencoding for retrieval</li>
                  <li class="model">E5 / BGE Embeddings</li>
                  <li class="model">Instructor Embeddings</li>
                  <li class="math-concept">Task-aware dense retrieval</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Advanced RAG Architectures</summary>
                <div class="math-desc">Multi-hop reasoning, fusion-in-decoder, retrieval refinement</div>
                <ul>
                  <li class="model">FiD (Fusion-in-Decoder)</li>
                  <li class="math-concept">Independent encoding, joint decoding</li>
                  <li class="model">REALM (Retrieval-Enhanced LM)</li>
                  <li class="math-concept">End-to-end retrieval learning</li>
                  <li class="model">RAG-Token / RAG-Sequence</li>
                  <li class="model">Self-RAG <span class="tag hot">reflection</span></li>
                  <li class="math-concept">Retrieval necessity prediction, self-critique</li>
                  <li class="model">Modular RAG</li>
                  <li class="model">Graph RAG</li>
                  <li class="math-concept">Knowledge graph enhanced retrieval</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Vector Databases & Search</summary>
                <div class="math-desc">Approximate nearest neighbor search, indexing algorithms, sharding</div>
                <ul>
                  <li class="model">Pinecone</li>
                  <li class="model">Weaviate</li>
                  <li class="model">Qdrant</li>
                  <li class="model">Chroma</li>
                  <li class="model">Milvus / Zilliz</li>
                  <li class="model">FAISS (Meta)</li>
                  <li class="math-concept">HNSW: Hierarchical Navigable Small World</li>
                  <li class="model">Annoy (Spotify)</li>
                  <li class="model">ScaNN (Google)</li>
                  <li class="math-concept">Product quantization, inverted file index</li>
                </ul>
              </details>
            </details>

            <!-- Causal AI & World Models -->
            <details>
              <summary>üåø <span class="branch">Causal AI & World Models</span> <span class="tag emerging">reasoning & simulation</span></summary>
              <div class="math-desc">Causal inference, structural equations, counterfactual reasoning, physics simulation</div>
              <details>
                <summary>üî∑ Causal Inference & Discovery</summary>
                <div class="math-desc">Directed acyclic graphs, do-calculus, structural causal models</div>
                <ul>
                  <li class="model">PC Algorithm</li>
                  <li class="math-concept">Constraint-based causal discovery</li>
                  <li class="model">GES (Greedy Equivalence Search)</li>
                  <li class="model">CausalML (Uber)</li>
                  <li class="model">DoWhy (Microsoft)</li>
                  <li class="math-concept">do(X=x): P(Y|do(X=x)) causal intervention</li>
                  <li class="model">Neural Causal Models</li>
                  <li class="math-concept">Structural equation models with neural networks</li>
                  <li class="model">CausalNex</li>
                  <li class="model">pgmpy (Probabilistic Graphical Models)</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ World Models & Simulation</summary>
                <div class="math-desc">Model-based reinforcement learning, physics simulation, predictive modeling</div>
                <ul>
                  <li class="model">DreamerV3 (DeepMind)</li>
                  <li class="math-concept">Latent world model: p(s_{t+1}|s_t,a_t)</li>
                  <li class="model">MuJoCo (Multi-Joint dynamics)</li>
                  <li class="math-concept">Contact dynamics, constraint solving</li>
                  <li class="model">Isaac Gym (NVIDIA)</li>
                  <li class="model">PyBullet</li>
                  <li class="model">Habitat (Meta)</li>
                  <li class="model">AI Habitat 2.0</li>
                  <li class="model">ThreeDWorld (MIT)</li>
                  <li class="math-concept">Physics-informed neural networks (PINNs)</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Digital Twins & Simulation</summary>
                <div class="math-desc">Real-time synchronization, digital-physical coupling, predictive maintenance</div>
                <ul>
                  <li class="model">NVIDIA Omniverse</li>
                  <li class="model">Unity ML-Agents</li>
                  <li class="model">Unreal Engine AI</li>
                  <li class="model">AnyLogic Simulation</li>
                  <li class="model">CARLA (Autonomous Driving)</li>
                  <li class="math-concept">Sensor simulation, traffic modeling</li>
                  <li class="model">Gazebo (Robotics)</li>
                  <li class="model">CoppeliaSim</li>
                </ul>
              </details>
            </details>

            <!-- Creative AI -->
            <details>
              <summary>üåø <span class="branch">Creative AI</span> <span class="tag hot">artistic generation</span></summary>
              <div class="math-desc">Style transfer, generative adversarial training, artistic style optimization</div>
              <details>
                <summary>üî∑ Art & Visual Generation</summary>
                <div class="math-desc">Neural style transfer, GANs for art, aesthetic loss functions</div>
                <ul>
                  <li class="model">DALL¬∑E 2/3 <span class="tag hot">text-to-image</span></li>
                  <li class="model">Midjourney v6</li>
                  <li class="model">Stable Diffusion Art</li>
                  <li class="model">Adobe Firefly</li>
                  <li class="model">RunwayML Gen-2</li>
                  <li class="model">StyleGAN for Art</li>
                  <li class="math-concept">Style loss: L_style = Œ£||G(F) - G(S)||¬≤</li>
                  <li class="model">Neural Style Transfer</li>
                  <li class="math-concept">Gram matrices, content + style loss</li>
                  <li class="model">ArtBreeder</li>
                  <li class="model">NightCafe Studio</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Music & Audio Generation</summary>
                <div class="math-desc">Harmonic analysis, rhythm modeling, spectral synthesis</div>
                <ul>
                  <li class="model">Suno AI <span class="tag hot">commercial music</span></li>
                  <li class="model">Udio <span class="tag hot">AI music</span></li>
                  <li class="model">MusicLM (Google)</li>
                  <li class="model">Jukebox (OpenAI)</li>
                  <li class="math-concept">VQ-VAE hierarchical audio modeling</li>
                  <li class="model">AIVA (AI Composer)</li>
                  <li class="model">Amper Music</li>
                  <li class="model">Soundraw</li>
                  <li class="model">MuseNet (OpenAI)</li>
                  <li class="math-concept">Transformer for symbolic music</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Creative Writing & Content</summary>
                <div class="math-desc">Language modeling for creativity, style control, narrative generation</div>
                <ul>
                  <li class="model">GPT-4 Creative Writing</li>
                  <li class="model">Claude Creative Assistant</li>
                  <li class="model">Jasper AI</li>
                  <li class="model">Copy.ai</li>
                  <li class="model">Writesonic</li>
                  <li class="model">NovelAI</li>
                  <li class="model">Sudowrite</li>
                  <li class="math-concept">Controllable generation, style conditioning</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Interactive & Procedural AI</summary>
                <div class="math-desc">Real-time generation, user interaction modeling, procedural algorithms</div>
                <ul>
                  <li class="model">AI Dungeon</li>
                  <li class="model">Character.AI</li>
                  <li class="model">Replika</li>
                  <li class="model">Procedural Content Generation</li>
                  <li class="math-concept">L-systems, cellular automata, noise functions</li>
                  <li class="model">Unity ML-Agents Creative</li>
                  <li class="model">Unreal Engine MetaHuman</li>
                </ul>
              </details>
            </details>

            <!-- Emerging & Research -->
            <details>
              <summary>üåø <span class="branch">Emerging AI Research</span> <span class="tag emerging">cutting-edge</span></summary>
              <div class="math-desc">Scaling laws: L(N) = aN^(-Œ±), compute-optimal training, emergent capabilities</div>
              <details>
                <summary>üî∑ Foundation Model Research</summary>
                <div class="math-desc">Scaling laws: L(N) = aN^(-Œ±), compute-optimal training</div>
                <ul>
                  <li class="model">GPT-5 <span class="tag emerging">rumored</span></li>
                  <li class="model">Claude 4+ <span class="tag emerging">future</span></li>
                  <li class="model">Gemini Advanced</li>
                  <li class="model">Meta LLaMA 4 <span class="tag emerging">development</span></li>
                  <li class="model">Mixture of Experts (MoE) scaling</li>
                  <li class="math-concept">Sparse expert routing, load balancing</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Novel Architectures</summary>
                <div class="math-desc">Alternative attention mechanisms, efficient transformers</div>
                <ul>
                  <li class="model">Mamba (State Space Models) <span class="tag emerging">efficiency</span></li>
                  <li class="math-concept">Selective state spaces, linear complexity</li>
                  <li class="model">RetNet (Alternative to Transformers)</li>
                  <li class="math-concept">Retention mechanism, parallel/recurrent duality</li>
                  <li class="model">Hyena (Subquadratic Attention)</li>
                  <li class="math-concept">Convolutional operators, implicit attention</li>
                  <li class="model">Kolmogorov-Arnold Networks</li>
                  <li class="math-concept">KAN: learnable activation functions on edges</li>
                  <li class="model">Liquid Neural Networks</li>
                  <li class="math-concept">Time-aware neurons, causal interactions</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ AGI Research</summary>
                <div class="math-desc">Multi-task learning, meta-learning, unified architectures</div>
                <ul>
                  <li class="model">OpenAI Q* <span class="tag emerging">rumored reasoning</span></li>
                  <li class="model">DeepMind Gato <span class="tag">generalist agent</span></li>
                  <li class="math-concept">Multi-modal tokenization, unified architecture</li>
                  <li class="model">AdA (Adaptive Agent)</li>
                  <li class="model">Artificial General Intelligence projects</li>
                </ul>
              </details>
              <details>
                <summary>üî∑ Neuromorphic Computing</summary>
                <div class="math-desc">Spiking neural networks, event-driven computation, brain-inspired architectures</div>
                <ul>
                  <li class="model">Intel Loihi 2</li>
                  <li class="math-concept">Spiking neural networks, asynchronous computation</li>
                  <li class="model">IBM TrueNorth</li>
                  <li class="model">SpiNNaker (Manchester)</li>
                  <li class="model">BrainChip Akida</li>
                  <li class="math-concept">Integrate-and-fire neurons, spike-timing dependent plasticity</li>
                  <li class="model">Memristor Networks</li>
                  <li class="math-concept">Resistive memory, in-memory computation</li>
                </ul>
              </details>
            </details>

          </details>
        </details>

        <!-- Alternative ML Approaches -->
        <details>
          <summary><span class="branch">Alternative ML Paradigms</span> <span class="tag">non-deep learning</span></summary>
          <div class="math-desc">Population-based algorithms, probabilistic inference, continual adaptation</div>
          <details>
            <summary>üî∑ Evolutionary & Genetic Algorithms</summary>
            <div class="math-desc">Population dynamics, fitness functions, genetic operators</div>
            <ul>
              <li class="model">NEAT (NeuroEvolution)</li>
              <li class="math-concept">Topology evolution, complexification</li>
              <li class="model">Genetic Programming</li>
              <li class="math-concept">Tree-based program evolution</li>
              <li class="model">Differential Evolution</li>
              <li class="math-concept">DE: x' = x_a + F(x_b - x_c)</li>
              <li class="model">Particle Swarm Optimization</li>
              <li class="math-concept">Swarm intelligence, velocity updates</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ Probabilistic & Bayesian ML</summary>
            <div class="math-desc">Prior distributions, posterior inference, uncertainty quantification</div>
            <ul>
              <li class="model">Gaussian Processes</li>
              <li class="math-concept">Kernel methods, posterior predictive distribution</li>
              <li class="model">Bayesian Neural Networks</li>
              <li class="math-concept">Weight uncertainty, variational inference</li>
              <li class="model">Variational Inference</li>
              <li class="math-concept">KL divergence minimization, ELBO optimization</li>
              <li class="model">Hidden Markov Models</li>
              <li class="math-concept">Forward-backward algorithm, Viterbi decoding</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ Online & Continual Learning</summary>
            <div class="math-desc">Catastrophic forgetting, memory replay, elastic weight consolidation</div>
            <ul>
              <li class="model">Online Gradient Descent</li>
              <li class="math-concept">Regret bounds, convergence rates</li>
              <li class="model">Elastic Weight Consolidation</li>
              <li class="math-concept">Fisher information matrix, importance weights</li>
              <li class="model">Progressive Neural Networks</li>
              <li class="math-concept">Lateral connections, task-specific columns</li>
              <li class="model">Meta-Learning (MAML)</li>
              <li class="math-concept">Gradient-based meta-learning, few-shot adaptation</li>
            </ul>
          </details>
        </details>

      </details>
    </section>

    <!-- Math -->
    <section class="card backbone-section">
      <details open>
        <summary><span class="branch">üìê Mathematical Foundations & Backbone</span> <span class="tag math">core theory</span></summary>
        <div class="desc">The mathematical bedrock that underlies all AI systems - from classical statistics to modern deep learning theory.</div>
        
        <details>
          <summary><span class="branch">Linear Algebra</span> <span class="tag math">vectors & matrices</span></summary>
          <div class="math-desc">Foundation of all neural network computations, transformations, and data representations.</div>
          <ul>
            <li class="math-concept">Vector Spaces & Linear Transformations</li>
            <li class="math-concept">Matrix Multiplication & Decomposition (SVD, LU, QR)</li>
            <li class="math-concept">Eigenvalues & Eigenvectors</li>
            <li class="math-concept">Principal Component Analysis (PCA)</li>
            <li class="math-concept">Tensor Operations (multi-dimensional arrays)</li>
          </ul>
          <div class="math-formula">
            Matrix multiplication: C = AB where C[i,j] = Œ£(k) A[i,k] * B[k,j]<br>
            Neural layer: y = œÉ(Wx + b) where W=weights, x=input, b=bias, œÉ=activation
          </div>
        </details>

        <details>
          <summary><span class="branch">Calculus & Optimization</span> <span class="tag math">learning algorithms</span></summary>
          <div class="math-desc">Drives gradient-based learning, backpropagation, and parameter optimization in neural networks.</div>
          <ul>
            <li class="math-concept">Partial Derivatives & Gradients</li>
            <li class="math-concept">Chain Rule (backpropagation foundation)</li>
            <li class="math-concept">Gradient Descent & Variants (SGD, Adam, AdaGrad)</li>
            <li class="math-concept">Lagrange Multipliers (constrained optimization)</li>
            <li class="math-concept">Convex Optimization</li>
            <li class="math-concept">Automatic Differentiation</li>
          </ul>
          <div class="math-formula">
            Gradient Descent: Œ∏(t+1) = Œ∏(t) - Œ±‚àáJ(Œ∏)<br>
            Backprop: ‚àÇL/‚àÇw = ‚àÇL/‚àÇy * ‚àÇy/‚àÇw (chain rule)<br>
            Adam: m(t) = Œ≤‚ÇÅm(t-1) + (1-Œ≤‚ÇÅ)g(t), v(t) = Œ≤‚ÇÇv(t-1) + (1-Œ≤‚ÇÇ)g(t)¬≤
          </div>
        </details>

        <details>
          <summary><span class="branch">Probability & Statistics</span> <span class="tag math">uncertainty & learning</span></summary>
          <div class="math-desc">Handles uncertainty, enables Bayesian learning, and provides theoretical foundations for many ML algorithms.</div>
          <ul>
            <li class="math-concept">Bayes' Theorem & Bayesian Inference</li>
            <li class="math-concept">Probability Distributions (Gaussian, Bernoulli, Categorical)</li>
            <li class="math-concept">Maximum Likelihood Estimation (MLE)</li>
            <li class="math-concept">Maximum A Posteriori (MAP) Estimation</li>
            <li class="math-concept">Central Limit Theorem</li>
            <li class="math-concept">Monte Carlo Methods</li>
            <li class="math-concept">Markov Chains & Stochastic Processes</li>
          </ul>
          <div class="math-formula">
            Bayes: P(A|B) = P(B|A)P(A) / P(B)<br>
            MLE: Œ∏* = argmax Œ† P(x_i|Œ∏)<br>
            Cross-entropy loss: L = -Œ£ y_i log(≈∑_i)
          </div>
        </details>

        <details>
          <summary><span class="branch">Information Theory</span> <span class="tag math">entropy & compression</span></summary>
          <div class="math-desc">Quantifies information content, drives attention mechanisms, and enables efficient model architectures.</div>
          <ul>
            <li class="math-concept">Entropy & Mutual Information</li>
            <li class="math-concept">Kullback-Leibler (KL) Divergence</li>
            <li class="math-concept">Cross-Entropy & Log-Likelihood</li>
            <li class="math-concept">Data Compression & Coding Theory</li>
            <li class="math-concept">Channel Capacity</li>
          </ul>
          <div class="math-formula">
            Entropy: H(X) = -Œ£ P(x)log P(x)<br>
            KL Divergence: D_KL(P||Q) = Œ£ P(x)log(P(x)/Q(x))<br>
            Attention: Attention(Q,K,V) = softmax(QK^T/‚àöd_k)V
          </div>
        </details>

        <details>
          <summary><span class="branch">Graph Theory & Discrete Math</span> <span class="tag math">structure & logic</span></summary>
          <div class="math-desc">Powers graph neural networks, combinatorial optimization, and symbolic AI reasoning systems.</div>
          <ul>
            <li class="math-concept">Graph Algorithms (BFS, DFS, Shortest Path)</li>
            <li class="math-concept">Adjacency Matrices & Laplacian</li>
            <li class="math-concept">Spectral Graph Theory</li>
            <li class="math-concept">Boolean Logic & Satisfiability</li>
            <li class="math-concept">Combinatorial Optimization</li>
            <li class="math-concept">Message Passing Algorithms</li>
          </ul>
          <div class="math-formula">
            GCN Layer: H^(l+1) = œÉ(D^(-1/2)AD^(-1/2)H^(l)W^(l))<br>
            Message Passing: h_v^(t+1) = UPDATE(h_v^(t), AGGREGATE({h_u^(t): u ‚àà N(v)}))
          </div>
        </details>

        <details>
          <summary><span class="branch">Functional Analysis & Kernel Methods</span> <span class="tag math">infinite dimensions</span></summary>
          <div class="math-desc">Provides theoretical foundations for SVMs, Gaussian processes, and function approximation theory.</div>
          <ul>
            <li class="math-concept">Reproducing Kernel Hilbert Spaces (RKHS)</li>
            <li class="math-concept">Kernel Trick & Kernel Functions</li>
            <li class="math-concept">Universal Approximation Theorem</li>
            <li class="math-concept">Fourier Analysis & Transforms</li>
            <li class="math-concept">Wavelets & Multi-resolution Analysis</li>
          </ul>
          <div class="math-formula">
            Kernel SVM: f(x) = Œ£ Œ±_i y_i K(x_i, x) + b<br>
            RBF Kernel: K(x,x') = exp(-||x-x'||¬≤/2œÉ¬≤)<br>
            Neural Tangent Kernel: K_NTK(x,x') = E[‚àáf(x;Œ∏)¬∑‚àáf(x';Œ∏)]
          </div>
        </details>

        <details>
          <summary><span class="branch">Numerical Methods & Computational Math</span> <span class="tag math">efficient computation</span></summary>
          <div class="math-desc">Enables fast, stable computation in high-dimensional spaces with finite precision arithmetic.</div>
          <ul>
            <li class="math-concept">Numerical Stability & Conditioning</li>
            <li class="math-concept">Fast Fourier Transform (FFT)</li>
            <li class="math-concept">Iterative Methods (Conjugate Gradient)</li>
            <li class="math-concept">Approximation Theory</li>
            <li class="math-concept">Finite Difference & Finite Element Methods</li>
            <li class="math-concept">Parallel & Distributed Algorithms</li>
          </ul>
          <div class="math-formula">
            Numerical stability: condition number Œ∫(A) = ||A|| ||A^(-1)||<br>
            FFT: O(n log n) instead of O(n¬≤) for DFT<br>
            BatchNorm: y = Œ≥(x-Œº)/œÉ + Œ≤ (normalize then scale/shift)
          </div>
        </details>

        <details>
          <summary><span class="branch">Topology & Manifold Learning</span> <span class="tag math">shape of data</span></summary>
          <div class="math-desc">Understanding the geometric structure of high-dimensional data and latent spaces in deep learning.</div>
          <ul>
            <li class="math-concept">Manifold Theory & Embeddings</li>
            <li class="math-concept">Riemannian Geometry</li>
            <li class="math-concept">Persistent Homology</li>
            <li class="math-concept">Dimensionality Reduction (t-SNE, UMAP)</li>
            <li class="math-concept">Geometric Deep Learning</li>
          </ul>
          <div class="math-formula">
            t-SNE: P(j|i) = exp(-||x_i-x_j||¬≤/2œÉ_i¬≤) / Œ£ exp(-||x_i-x_k||¬≤/2œÉ_i¬≤)<br>
            Manifold assumption: high-dim data lies on low-dim manifold
          </div>
        </details>

        <details>
          <summary><span class="branch">Game Theory & Decision Theory</span> <span class="tag math">strategic learning</span></summary>
          <div class="math-desc">Foundation for multi-agent systems, GANs, reinforcement learning, and AI safety research.</div>
          <ul>
            <li class="math-concept">Nash Equilibrium & Game Solutions</li>
            <li class="math-concept">Minimax & Zero-sum Games</li>
            <li class="math-concept">Mechanism Design</li>
            <li class="math-concept">Auction Theory</li>
            <li class="math-concept">Markov Decision Processes (MDPs)</li>
            <li class="math-concept">Multi-Agent Reinforcement Learning</li>
          </ul>
          <div class="math-formula">
            Minimax: min_Œ∏ max_œÜ V(Œ∏,œÜ) (GANs)<br>
            Bellman: V(s) = max_a Œ£ P(s'|s,a)[R(s,a,s') + Œ≥V(s')]<br>
            Nash: strategies where no player benefits from unilateral change
          </div>
        </details>

        <details>
          <summary><span class="branch">Measure Theory & Advanced Probability</span> <span class="tag math">rigorous foundations</span></summary>
          <div class="math-desc">Provides rigorous mathematical foundations for probability theory, stochastic processes, and learning theory.</div>
          <ul>
            <li class="math-concept">œÉ-algebras & Measure Spaces</li>
            <li class="math-concept">Lebesgue Integration</li>
            <li class="math-concept">Martingales & Stopping Times</li>
            <li class="math-concept">Concentration Inequalities</li>
            <li class="math-concept">PAC Learning Theory</li>
            <li class="math-concept">VC Dimension & Generalization Bounds</li>
          </ul>
          <div class="math-formula">
            Hoeffding: P(|S_n - E[S_n]| ‚â• t) ‚â§ 2exp(-2t¬≤/n)<br>
            PAC: P(error ‚â§ Œµ) ‚â• 1-Œ¥ with sufficient samples<br>
            VC bound: generalization error ‚â§ empirical error + complexity term
          </div>
        </details>

      </details>
    </section>

    <!-- Metaheuristics & Optimization -->
    <section class="card backbone-section">
      <details open>
        <summary><span class="branch">üîß Metaheuristics & Optimization Paradigms</span> <span class="tag">algorithmic strategies</span></summary>
        <div class="desc">Applied optimization strategies and search algorithms that leverage mathematical foundations to solve complex problems across domains.</div>
        
        <details>
          <summary><span class="branch">Classical Optimization Algorithms</span> <span class="tag">deterministic methods</span></summary>
          <div class="math-desc">Direct application of calculus and linear algebra for systematic optimization.</div>
          <details>
            <summary>üî∑ Gradient-Based Methods</summary>
            <ul>
              <li class="model">Steepest Descent</li>
              <li class="math-concept">Œ∏(t+1) = Œ∏(t) - Œ±‚àáf(Œ∏(t))</li>
              <li class="model">Newton's Method</li>
              <li class="math-concept">Œ∏(t+1) = Œ∏(t) - [‚àá¬≤f(Œ∏(t))]‚Åª¬π‚àáf(Œ∏(t))</li>
              <li class="model">Quasi-Newton (BFGS, L-BFGS)</li>
              <li class="math-concept">Hessian approximation, limited memory variants</li>
              <li class="model">Conjugate Gradient</li>
              <li class="math-concept">Orthogonal search directions, quadratic convergence</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ Constrained Optimization</summary>
            <ul>
              <li class="model">Sequential Quadratic Programming (SQP)</li>
              <li class="math-concept">Quadratic subproblems, KKT conditions</li>
              <li class="model">Interior Point Methods</li>
              <li class="math-concept">Barrier functions, primal-dual algorithms</li>
              <li class="model">Active Set Methods</li>
              <li class="math-concept">Working set strategy, constraint identification</li>
              <li class="model">Penalty & Augmented Lagrangian</li>
              <li class="math-concept">‚Ñì(x,Œª,Œº) = f(x) + Œª·µÄh(x) + Œº/2||h(x)||¬≤</li>
            </ul>
          </details>
        </details>

        <details>
          <summary><span class="branch">Metaheuristic Methods</span> <span class="tag">nature-inspired</span></summary>
          <div class="math-desc">Bio-inspired and physics-inspired algorithms for global optimization and search.</div>
          <details>
            <summary>üî∑ Evolutionary Algorithms</summary>
            <ul>
              <li class="model">Genetic Algorithm (GA)</li>
              <li class="math-concept">Selection, crossover, mutation operators</li>
              <li class="model">Evolution Strategy (ES)</li>
              <li class="math-concept">(Œº,Œª)-ES: Œº parents, Œª offspring, selection</li>
              <li class="model">Differential Evolution (DE)</li>
              <li class="math-concept">v = x_r1 + F(x_r2 - x_r3), mutation factor F</li>
              <li class="model">Genetic Programming (GP)</li>
              <li class="math-concept">Tree-based program evolution, parse trees</li>
              <li class="model">NSGA-II/III</li>
              <li class="math-concept">Multi-objective optimization, Pareto dominance</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ Swarm Intelligence</summary>
            <ul>
              <li class="model">Particle Swarm Optimization (PSO)</li>
              <li class="math-concept">v(t+1) = w¬∑v(t) + c‚ÇÅr‚ÇÅ(p_best - x) + c‚ÇÇr‚ÇÇ(g_best - x)</li>
              <li class="model">Ant Colony Optimization (ACO)</li>
              <li class="math-concept">Pheromone trails, probabilistic path construction</li>
              <li class="model">Artificial Bee Colony (ABC)</li>
              <li class="math-concept">Employed/onlooker/scout bees, waggle dance</li>
              <li class="model">Firefly Algorithm</li>
              <li class="math-concept">Attractiveness Œ≤‚ÇÄe^(-Œ≥r¬≤), distance-based movement</li>
              <li class="model">Grey Wolf Optimizer (GWO)</li>
              <li class="math-concept">Œ±, Œ≤, Œ¥ wolves hierarchy, encircling prey</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ Physics-Based Algorithms</summary>
            <ul>
              <li class="model">Simulated Annealing (SA)</li>
              <li class="math-concept">P(accept) = exp(-ŒîE/kT), cooling schedule</li>
              <li class="model">Gravitational Search Algorithm</li>
              <li class="math-concept">F = G¬∑M‚ÇÅM‚ÇÇ/R¬≤, gravitational force</li>
              <li class="model">Big Bang-Big Crunch</li>
              <li class="math-concept">Expansion and contraction phases</li>
              <li class="model">Harmony Search</li>
              <li class="math-concept">HMCR, PAR parameters, pitch adjustment</li>
              <li class="model">Water Cycle Algorithm</li>
              <li class="math-concept">Evaporation, condensation, precipitation</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ Human-Based Algorithms</summary>
            <ul>
              <li class="model">Teaching-Learning Based Optimization</li>
              <li class="math-concept">Teacher phase, learner phase interactions</li>
              <li class="model">Imperialist Competitive Algorithm</li>
              <li class="math-concept">Empires, colonies, assimilation policy</li>
              <li class="model">Social Spider Optimization</li>
              <li class="math-concept">Vibrations on web, mating behavior</li>
              <li class="model">Brain Storm Optimization</li>
              <li class="math-concept">Brainstorming process, idea generation</li>
            </ul>
          </details>
        </details>

        <details>
          <summary><span class="branch">Specialized Search Algorithms</span> <span class="tag">domain-specific</span></summary>
          <div class="math-desc">Tailored algorithms for specific problem structures and constraints.</div>
          <details>
            <summary>üî∑ Tree & Graph Search</summary>
            <ul>
              <li class="model">A* Search</li>
              <li class="math-concept">f(n) = g(n) + h(n), admissible heuristic</li>
              <li class="model">Branch and Bound</li>
              <li class="math-concept">Lower bounds, pruning strategies</li>
              <li class="model">Monte Carlo Tree Search (MCTS)</li>
              <li class="math-concept">UCB1: xÃÑ·µ¢ + ‚àö(2lnn/n·µ¢), exploration-exploitation</li>
              <li class="model">Minimax with Alpha-Beta</li>
              <li class="math-concept">Game tree pruning, Œ±-Œ≤ cutoffs</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ Local Search Methods</summary>
            <ul>
              <li class="model">Hill Climbing</li>
              <li class="math-concept">Greedy local improvement, local optima</li>
              <li class="model">Tabu Search</li>
              <li class="math-concept">Tabu list, aspiration criteria, memory structures</li>
              <li class="model">Variable Neighborhood Search</li>
              <li class="math-concept">Systematic neighborhood changes</li>
              <li class="model">Iterated Local Search</li>
              <li class="math-concept">Perturbation and local search cycles</li>
              <li class="model">GRASP (Greedy Randomized)</li>
              <li class="math-concept">Construction + local search phases</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ Multiple Criteria Decision Making (MCDM)</summary>
            <div class="math-desc">Decision-making frameworks for problems with multiple conflicting objectives and criteria.</div>
            <ul>
              <li class="model">AHP (Analytic Hierarchy Process)</li>
              <li class="math-concept">Pairwise comparison matrix, eigenvalue method, consistency ratio</li>
              <li class="model">TOPSIS (Technique for Order Preference)</li>
              <li class="math-concept">Ideal/anti-ideal solutions, Euclidean distance, relative closeness</li>
              <li class="model">ELECTRE (Elimination Et Choix)</li>
              <li class="math-concept">Concordance/discordance indices, outranking relations</li>
              <li class="model">PROMETHEE (Preference Ranking)</li>
              <li class="math-concept">Preference functions, net flows, partial preorder</li>
              <li class="model">VIKOR (Multicriteria Optimization)</li>
              <li class="math-concept">S*·µ¢ = Œ£w‚±º(f‚±º*-f‚±º(a·µ¢))/(f‚±º*-f‚±º‚Åª), compromise ranking</li>
              <li class="model">DEA (Data Envelopment Analysis)</li>
              <li class="math-concept">Efficiency frontier, CCR/BCC models, linear programming</li>
              <li class="model">Fuzzy MCDM Methods</li>
              <li class="math-concept">Fuzzy AHP, fuzzy TOPSIS, linguistic variables</li>
              <li class="model">MAUT/MAVT (Multi-Attribute Utility)</li>
              <li class="math-concept">Utility functions, independence assumptions</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ Hybrid & Multi-Objective</summary>
            <ul>
              <li class="model">Memetic Algorithms</li>
              <li class="math-concept">Evolution + local search combination</li>
              <li class="model">MOEA/D (Multi-Objective EA)</li>
              <li class="math-concept">Decomposition approach, weight vectors</li>
              <li class="model">SPEA2 (Strength Pareto)</li>
              <li class="math-concept">Strength calculation, archive maintenance</li>
              <li class="model">Scatter Search</li>
              <li class="math-concept">Reference set, diversification generation</li>
            </ul>
          </details>
        </details>

        <details>
          <summary><span class="branch">Optimization Test Functions & Benchmarks</span> <span class="tag">evaluation</span></summary>
          <div class="math-desc">Standard benchmark problems for algorithm testing and comparison.</div>
          <details>
            <summary>üî∑ Classical Test Functions</summary>
            <ul>
              <li class="model">Sphere Function</li>
              <li class="math-concept">f(x) = Œ£x·µ¢¬≤, unimodal, separable</li>
              <li class="model">Rosenbrock Function</li>
              <li class="math-concept">f(x) = Œ£[100(x·µ¢‚Çä‚ÇÅ-x·µ¢¬≤)¬≤ + (1-x·µ¢)¬≤], banana-shaped</li>
              <li class="model">Rastrigin Function</li>
              <li class="math-concept">f(x) = An + Œ£[x·µ¢¬≤ - A cos(2œÄx·µ¢)], multimodal</li>
              <li class="model">Ackley Function</li>
              <li class="math-concept">Exponential and cosine terms, many local optima</li>
              <li class="model">Griewank Function</li>
              <li class="math-concept">f(x) = 1 + (1/4000)Œ£x·µ¢¬≤ - Œ† cos(x·µ¢/‚àöi)</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ CEC Competition Functions</summary>
            <ul>
              <li class="model">CEC 2013/2017/2020 Suites</li>
              <li class="math-concept">Shifted, rotated, composed functions</li>
              <li class="model">Large-Scale Optimization</li>
              <li class="math-concept">High-dimensional problems, scalability testing</li>
              <li class="model">Multi-Modal Optimization</li>
              <li class="math-concept">Multiple global optima, niching methods</li>
              <li class="model">Expensive Optimization</li>
              <li class="math-concept">Limited function evaluations, surrogate models</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ Real-World Inspired Problems</summary>
            <ul>
              <li class="model">Traveling Salesman Problem (TSP)</li>
              <li class="math-concept">Combinatorial optimization, Hamiltonian cycle</li>
              <li class="model">Knapsack Problems</li>
              <li class="math-concept">0-1, bounded, unbounded variants</li>
              <li class="model">Vehicle Routing Problem</li>
              <li class="math-concept">Capacity constraints, time windows</li>
              <li class="model">Job Shop Scheduling</li>
              <li class="math-concept">Makespan minimization, precedence constraints</li>
              <li class="model">Portfolio Optimization</li>
              <li class="math-concept">Risk-return tradeoff, correlation matrices</li>
            </ul>
          </details>
        </details>

        <details>
          <summary><span class="branch">Modern Optimization Paradigms</span> <span class="tag hot">contemporary approaches</span></summary>
          <div class="math-desc">Recent developments combining traditional methods with machine learning.</div>
          <details>
            <summary>üî∑ Learning-Augmented Optimization</summary>
            <ul>
              <li class="model">Neural Evolution Strategies</li>
              <li class="math-concept">ES with neural networks, policy gradients</li>
              <li class="model">Differentiable Evolution</li>
              <li class="math-concept">Gradient-based evolution, relaxed operations</li>
              <li class="model">Meta-Learning for Optimization</li>
              <li class="math-concept">Learning to optimize, algorithm configuration</li>
              <li class="model">Bayesian Optimization</li>
              <li class="math-concept">Gaussian process surrogates, acquisition functions</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ Quantum-Inspired Algorithms</summary>
            <ul>
              <li class="model">Quantum Evolutionary Algorithm</li>
              <li class="math-concept">Quantum bit representation, rotation gates</li>
              <li class="model">Quantum Particle Swarm</li>
              <li class="math-concept">Quantum mechanics principles in PSO</li>
              <li class="model">Quantum Annealing</li>
              <li class="math-concept">Adiabatic quantum computation, Ising models</li>
            </ul>
          </details>
          <details>
            <summary>üî∑ Distributed & Parallel Optimization</summary>
            <ul>
              <li class="model">Island Model GA</li>
              <li class="math-concept">Population islands, migration strategies</li>
              <li class="model">Asynchronous Evolution</li>
              <li class="math-concept">Non-blocking parallel evaluation</li>
              <li class="model">MapReduce Optimization</li>
              <li class="math-concept">Distributed fitness evaluation, reduce operations</li>
              <li class="model">GPU-Accelerated Algorithms</li>
              <li class="math-concept">Massive parallelization, CUDA implementations</li>
            </ul>
          </details>
        </details>

      </details>
    </section>

    <footer>
      *This comprehensive family tree includes both established and emerging models with their mathematical foundations. Some future versions are speculative. The mathematical descriptions provide the theoretical backbone underlying each AI system.
      <br><br>
      <strong>Last updated:</strong> August 2025 | 
      <a href="#" onclick="expandAll()">Expand All</a> | 
      <a href="#" onclick="collapseAll()">Collapse All</a>
    </footer>
  </div>

  <script src="script.js"></script>
</body>
</html>